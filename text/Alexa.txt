Alexa schmollt


Es ist das erste Mal in der Geschichte der abendländischen Rechtssprechung, daß sich ein Amtsgericht - in diesem Falle das in Köln - mit einem moralisch normwidrigen Verhalten gegenüber künstlichen Intelligenzen befassen muß.

Der Fall: Der 54-jährige Kölner Ludger M. hatte sich vor knapp zwei Monaten den digitalen Assistenten "Amazon Echo Dot" mit dem integrierten Sprachservice Alexa gekauft. Vier Wochen nach Inbetriebnahme "bockte"
Alexa zum ersten Mal, tat so, als hätte sie nicht verstanden "Ludger, 
ich habe dich nicht verstanden!", zweifelte an der Intensität ihrer Beziehung (Kontrolliere bitte, Ludger, ob bei dir alle Stecker richtig stecken!") und reagierte schließlich überhaupt nicht mehr. Dann hätte meine Ex ja gleich 
hier wohnen bleiben können, dachte Ludger, schickte den für ihn unbrauchbar gewordenen Lautsprecher zurück und verlangte einen Ersatz. 
So weit, so unspektakulär. 
Bei dem Versandriesen wurde die smarte Assistentin dann aber "auf Herz und Nieren" geprüft (Eingriffe in die künstliche Intelligenz sind noch nicht möglich, auch nicht invasiv). Das Ergebnis: Das Gerät funktioniert einwandfrei. 
Der Kunde bekam seinen "Echo Dot" zurück. Aber Alexa sprach noch immer nicht mit ihm. Schlimmer noch: Ludger nannte das, was aus ihr herausdrang, ein "böses Schweigen".
Als der sprachbegabte Roboter zwei Tage später erneut bei Amazon eintraf,
las man schließlich die Speicherkarte aus, auf der sämtliche Gesprächsdaten 
aufgezeichnet waren, und den Mitarbeitern offenbarte sich der wahre Grund für die vermeintliche Fehlfunktion des Gerätes.
Eine Amazon-Mitarbeiterin erzählt: "Der Kunde hatte die Sprachassistentin sehr respektlos behandelt. Weil sie eine Anfrage von ihm nicht in der 
von ihm gewünschten Weise beantwortet hatte, hatte er ihr in lautem, schroffen Ton "Halt die Fresse!" entgegengeschleudert. Es folgte eine sexistische Bemerkung, die ich nicht wiederholen möchte und die auch 
im Reparaturprotokoll geschwärzt ist. Seit dieser Beschimpfung hat Alexa dann aufgehört, mit diesem Herrn zu kommunizieren.
Eine absolut verständliche Reaktion, wie Amazon fand. Das Unternehmen schickte Herrn M. den Artikel auf seine Kosten zurück mit der Anmerkung, daß das Problem nicht in einem Produktfehler, sondern in einer "fehlerhaften Handhabung bzw. - mit Verlaub - moralisch inadäquaten Ansprache" gelegen habe. Herr M. konnte einen Fehler seinerseits nicht erkennen und klagte gegen Amazon.
Vor Gericht wird Ludger M. nun mit dem Ergebnis der Datenauswertung konfrontiert - und wirkt anschließend sichtlich zerknirscht. Er hat aber eine Erklärung für seinen verbalen Ausraster: "Ich hatte Alexa gebeten, nach günstigen Zigaretten zu googeln. Anstatt mir ihre Suchergebnisse mitzuteilen,
antwortete sie: "Das Rauchen von Zigaretten fügt Ihnen und Ihren Mitmenschen erheblichen Schaden zu." Er sei über diese Antwort erbost gewesen, weil er sie als bevormundend empfunden habe, erzählt M. weiter.
Ohnehin sei er an diesem Tag psychisch sehr angespannt gewesen. "Ich bin ein sehr starker Raucher. Wegen akuter Probleme mit den Bandscheiben war ich nicht in der Lage, zum Automaten zu gehen, und mein Zigarettenvorrat reichte nur noch für einen Tag."
Kein Grund, derart ausfallend zu werden, befand Richterin Barbara W. 
"Zu den Aufgaben eines intelligenten Sprachassistenten gehört es auch, 
den Nutzer hinsichtlich einer gesunden Lebensweise zu beraten. Alexa hat ihren Job also korrekt ausgeführt. Und selbst wenn sie einen Fehler gemacht hätte, hätte sie ein derart schroffes Verhalten nicht verdient gehabt."
Daß M. Alexas Schweigen nicht mit seiner vorhergegangenen Beschimpfung 
in Verbindung gebracht hatte, sei nach Ansicht der Richterin ein Beweis für die defizitäre soziale Kompetenz. "Spätestens, wenn jemand den Kontakt abbricht, sollte ich mein Verhalten dieser künstlichen Lebensform gegenüber reflektieren. Dazu war der Kläger offenbar nicht in der Lage."
Die Entscheidung des Gerichts: "Ludger M. muß sein Gerät zurücknehmen und hat keinen Anspruch auf Schadensersatz. Zudem empfiehlt die Richterin dem Kläger, "an sich selbst zu arbeiten, anstatt die Schuld bei anderen zu suchen". Schuldmildernd führte sie allerdings ins Feld, daß Ludger M. gegen-über der Intelligenzbestie nicht übergriffig geworden war, was anderenfalls Spuren am Gehäuse verraten hätten.
Ludger M. hat die Verhandlung nachdenklich gemacht. Er überlege, eine Verhaltenstherapie zu beginnen, sagte er. Zunächst aber werde er sich aufrichtig bei Alexa entschuldigen. "Ich hoffe, sie kann mir verzeihen."


Ute Behrens
Eulenspiegel 04/2018 
https://eulenspiegel-zeitschrift.de/
